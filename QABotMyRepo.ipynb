{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6eX8b7vdCVJF",
        "outputId": "55d3bc35-0338-4df8-ffc8-5f0240da1fdc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pypdf in e:\\generative ai projects\\gradio chatbot\\venv\\lib\\site-packages (3.9.0)\n",
            "Requirement already satisfied: python-dotenv in e:\\generative ai projects\\gradio chatbot\\venv\\lib\\site-packages (1.0.0)\n",
            "Collecting tabulate\n",
            "  Using cached tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
            "Installing collected packages: tabulate\n",
            "Successfully installed tabulate-0.9.0\n"
          ]
        }
      ],
      "source": [
        "# Requirement\n",
        "!pip install openai -q\n",
        "!pip install langchain -q\n",
        "!pip install chromadb -q\n",
        "!pip install tiktoken -q\n",
        "!pip install unstructured[local-inference] -q\n",
        "!pip install pypdf\n",
        "!pip install gradio -q\n",
        "!pip install python-dotenv\n",
        "!pip install tabulate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0E8NympDGVK",
        "outputId": "e0af0891-576e-4be6-9167-1738e93c7de8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9.5.0\n"
          ]
        }
      ],
      "source": [
        "#nb the default google colab runtime loads PIL 8.4.0 and it won't work with unstructured document loader (see above dependency). \n",
        "import PIL\n",
        "print(PIL.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "KRwnYjP0DKA6",
        "outputId": "1995ef10-b8e4-4e5b-bc21-9a65c0cfa947"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "^C\n",
            "Requirement already satisfied: Pillow in e:\\generative ai projects\\gradio chatbot\\venv\\lib\\site-packages (9.5.0)\n",
            "9.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall Pillow\n",
        "!pip install --upgrade Pillow\n",
        "print(PIL.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JLHudc48C-l5"
      },
      "outputs": [],
      "source": [
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "load_dotenv()\n",
        "#print(os.getenv(\"OPENAI_API_KEY\"))\n",
        "\n",
        "#os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
        "\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "llm = ChatOpenAI(temperature=0,model_name=\"gpt-4\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IaywQ5R1DkBW",
        "outputId": "8f23ce07-39b2-4882-fb07-6347cc4fc492"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[93], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m documents \u001b[39m=\u001b[39m []\n\u001b[0;32m     15\u001b[0m \u001b[39mfor\u001b[39;00m loader \u001b[39min\u001b[39;00m loaders:\n\u001b[1;32m---> 16\u001b[0m     documents\u001b[39m.\u001b[39mextend(loader\u001b[39m.\u001b[39;49mload())\n\u001b[0;32m     18\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTotal number of documents: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(documents)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
            "File \u001b[1;32me:\\Generative AI Projects\\Gradio Chatbot\\venv\\lib\\site-packages\\langchain\\document_loaders\\directory.py:108\u001b[0m, in \u001b[0;36mDirectoryLoader.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    107\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m items:\n\u001b[1;32m--> 108\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mload_file(i, p, docs, pbar)\n\u001b[0;32m    110\u001b[0m \u001b[39mif\u001b[39;00m pbar:\n\u001b[0;32m    111\u001b[0m     pbar\u001b[39m.\u001b[39mclose()\n",
            "File \u001b[1;32me:\\Generative AI Projects\\Gradio Chatbot\\venv\\lib\\site-packages\\langchain\\document_loaders\\directory.py:63\u001b[0m, in \u001b[0;36mDirectoryLoader.load_file\u001b[1;34m(self, item, path, docs, pbar)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[39mif\u001b[39;00m _is_visible(item\u001b[39m.\u001b[39mrelative_to(path)) \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mload_hidden:\n\u001b[0;32m     62\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 63\u001b[0m         sub_docs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloader_cls(\u001b[39mstr\u001b[39;49m(item), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloader_kwargs)\u001b[39m.\u001b[39;49mload()\n\u001b[0;32m     64\u001b[0m         docs\u001b[39m.\u001b[39mextend(sub_docs)\n\u001b[0;32m     65\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
            "File \u001b[1;32me:\\Generative AI Projects\\Gradio Chatbot\\venv\\lib\\site-packages\\langchain\\document_loaders\\unstructured.py:71\u001b[0m, in \u001b[0;36mUnstructuredBaseLoader.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[Document]:\n\u001b[0;32m     70\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Load file.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 71\u001b[0m     elements \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_elements()\n\u001b[0;32m     72\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39melements\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m     73\u001b[0m         docs: List[Document] \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m()\n",
            "File \u001b[1;32me:\\Generative AI Projects\\Gradio Chatbot\\venv\\lib\\site-packages\\langchain\\document_loaders\\unstructured.py:108\u001b[0m, in \u001b[0;36mUnstructuredFileLoader._get_elements\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_elements\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List:\n\u001b[0;32m    106\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39munstructured\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpartition\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mauto\u001b[39;00m \u001b[39mimport\u001b[39;00m partition\n\u001b[1;32m--> 108\u001b[0m     \u001b[39mreturn\u001b[39;00m partition(filename\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfile_path, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39munstructured_kwargs)\n",
            "File \u001b[1;32me:\\Generative AI Projects\\Gradio Chatbot\\venv\\lib\\site-packages\\unstructured\\partition\\auto.py:155\u001b[0m, in \u001b[0;36mpartition\u001b[1;34m(filename, content_type, file, file_filename, url, include_page_breaks, strategy, encoding, paragraph_grouper, headers, ssl_verify, ocr_languages, pdf_infer_table_structure, xml_keep_tags)\u001b[0m\n\u001b[0;32m    149\u001b[0m     elements \u001b[39m=\u001b[39m partition_md(\n\u001b[0;32m    150\u001b[0m         filename\u001b[39m=\u001b[39mfilename,\n\u001b[0;32m    151\u001b[0m         file\u001b[39m=\u001b[39mfile,\n\u001b[0;32m    152\u001b[0m         include_page_breaks\u001b[39m=\u001b[39minclude_page_breaks,\n\u001b[0;32m    153\u001b[0m     )\n\u001b[0;32m    154\u001b[0m \u001b[39melif\u001b[39;00m filetype \u001b[39m==\u001b[39m FileType\u001b[39m.\u001b[39mPDF:\n\u001b[1;32m--> 155\u001b[0m     elements \u001b[39m=\u001b[39m partition_pdf(\n\u001b[0;32m    156\u001b[0m         filename\u001b[39m=\u001b[39;49mfilename,  \u001b[39m# type: ignore\u001b[39;49;00m\n\u001b[0;32m    157\u001b[0m         file\u001b[39m=\u001b[39;49mfile,  \u001b[39m# type: ignore\u001b[39;49;00m\n\u001b[0;32m    158\u001b[0m         url\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    159\u001b[0m         include_page_breaks\u001b[39m=\u001b[39;49minclude_page_breaks,\n\u001b[0;32m    160\u001b[0m         encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[0;32m    161\u001b[0m         infer_table_structure\u001b[39m=\u001b[39;49mpdf_infer_table_structure,\n\u001b[0;32m    162\u001b[0m         strategy\u001b[39m=\u001b[39;49mstrategy,\n\u001b[0;32m    163\u001b[0m         ocr_languages\u001b[39m=\u001b[39;49mocr_languages,\n\u001b[0;32m    164\u001b[0m     )\n\u001b[0;32m    165\u001b[0m \u001b[39melif\u001b[39;00m (filetype \u001b[39m==\u001b[39m FileType\u001b[39m.\u001b[39mPNG) \u001b[39mor\u001b[39;00m (filetype \u001b[39m==\u001b[39m FileType\u001b[39m.\u001b[39mJPG):\n\u001b[0;32m    166\u001b[0m     elements \u001b[39m=\u001b[39m partition_image(\n\u001b[0;32m    167\u001b[0m         filename\u001b[39m=\u001b[39mfilename,  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[0;32m    168\u001b[0m         file\u001b[39m=\u001b[39mfile,  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    171\u001b[0m         ocr_languages\u001b[39m=\u001b[39mocr_languages,\n\u001b[0;32m    172\u001b[0m     )\n",
            "File \u001b[1;32me:\\Generative AI Projects\\Gradio Chatbot\\venv\\lib\\site-packages\\unstructured\\file_utils\\filetype.py:370\u001b[0m, in \u001b[0;36madd_metadata_with_filetype.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    368\u001b[0m \u001b[39m@wraps\u001b[39m(func)\n\u001b[0;32m    369\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 370\u001b[0m     elements \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    371\u001b[0m     sig \u001b[39m=\u001b[39m inspect\u001b[39m.\u001b[39msignature(func)\n\u001b[0;32m    372\u001b[0m     params \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mdict\u001b[39m(\u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args)), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
            "File \u001b[1;32me:\\Generative AI Projects\\Gradio Chatbot\\venv\\lib\\site-packages\\unstructured\\partition\\pdf.py:78\u001b[0m, in \u001b[0;36mpartition_pdf\u001b[1;34m(filename, file, url, template, token, include_page_breaks, strategy, infer_table_structure, encoding, ocr_languages)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Parses a pdf document into a list of interpreted elements.\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[39m----------\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[39m    to isntall the appropriate Tesseract language pack.\u001b[39;00m\n\u001b[0;32m     76\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     77\u001b[0m exactly_one(filename\u001b[39m=\u001b[39mfilename, file\u001b[39m=\u001b[39mfile)\n\u001b[1;32m---> 78\u001b[0m \u001b[39mreturn\u001b[39;00m partition_pdf_or_image(\n\u001b[0;32m     79\u001b[0m     filename\u001b[39m=\u001b[39;49mfilename,\n\u001b[0;32m     80\u001b[0m     file\u001b[39m=\u001b[39;49mfile,\n\u001b[0;32m     81\u001b[0m     url\u001b[39m=\u001b[39;49murl,\n\u001b[0;32m     82\u001b[0m     template\u001b[39m=\u001b[39;49mtemplate,\n\u001b[0;32m     83\u001b[0m     token\u001b[39m=\u001b[39;49mtoken,\n\u001b[0;32m     84\u001b[0m     include_page_breaks\u001b[39m=\u001b[39;49minclude_page_breaks,\n\u001b[0;32m     85\u001b[0m     strategy\u001b[39m=\u001b[39;49mstrategy,\n\u001b[0;32m     86\u001b[0m     infer_table_structure\u001b[39m=\u001b[39;49minfer_table_structure,\n\u001b[0;32m     87\u001b[0m     encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[0;32m     88\u001b[0m     ocr_languages\u001b[39m=\u001b[39;49mocr_languages,\n\u001b[0;32m     89\u001b[0m )\n",
            "File \u001b[1;32me:\\Generative AI Projects\\Gradio Chatbot\\venv\\lib\\site-packages\\unstructured\\partition\\pdf.py:140\u001b[0m, in \u001b[0;36mpartition_pdf_or_image\u001b[1;34m(filename, file, url, template, token, is_image, include_page_breaks, strategy, infer_table_structure, encoding, ocr_languages)\u001b[0m\n\u001b[0;32m    129\u001b[0m         layout_elements \u001b[39m=\u001b[39m _partition_pdf_or_image_local(\n\u001b[0;32m    130\u001b[0m             filename\u001b[39m=\u001b[39mfilename,\n\u001b[0;32m    131\u001b[0m             file\u001b[39m=\u001b[39mspooled_to_bytes_io_if_needed(file),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    136\u001b[0m             ocr_languages\u001b[39m=\u001b[39mocr_languages,\n\u001b[0;32m    137\u001b[0m         )\n\u001b[0;32m    139\u001b[0m \u001b[39melif\u001b[39;00m strategy \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mfast\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m--> 140\u001b[0m     \u001b[39mreturn\u001b[39;00m _partition_pdf_with_pdfminer(\n\u001b[0;32m    141\u001b[0m         filename\u001b[39m=\u001b[39;49mfilename,\n\u001b[0;32m    142\u001b[0m         file\u001b[39m=\u001b[39;49mspooled_to_bytes_io_if_needed(file),\n\u001b[0;32m    143\u001b[0m         include_page_breaks\u001b[39m=\u001b[39;49minclude_page_breaks,\n\u001b[0;32m    144\u001b[0m         encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[0;32m    145\u001b[0m     )\n\u001b[0;32m    147\u001b[0m \u001b[39melif\u001b[39;00m strategy \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mocr_only\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    148\u001b[0m     \u001b[39m# NOTE(robinson): Catches file conversion warnings when running with PDFs\u001b[39;00m\n\u001b[0;32m    149\u001b[0m     \u001b[39mwith\u001b[39;00m warnings\u001b[39m.\u001b[39mcatch_warnings():\n",
            "File \u001b[1;32me:\\Generative AI Projects\\Gradio Chatbot\\venv\\lib\\site-packages\\unstructured\\utils.py:43\u001b[0m, in \u001b[0;36mrequires_dependencies.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(missing_deps) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m     35\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\n\u001b[0;32m     36\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFollowing dependencies are missing: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(missing_deps)\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     37\u001b[0m         \u001b[39m+\u001b[39m (\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     41\u001b[0m         ),\n\u001b[0;32m     42\u001b[0m     )\n\u001b[1;32m---> 43\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
            "File \u001b[1;32me:\\Generative AI Projects\\Gradio Chatbot\\venv\\lib\\site-packages\\unstructured\\partition\\pdf.py:248\u001b[0m, in \u001b[0;36m_partition_pdf_with_pdfminer\u001b[1;34m(filename, file, include_page_breaks, encoding)\u001b[0m\n\u001b[0;32m    246\u001b[0m     \u001b[39mwith\u001b[39;00m open_filename(filename, \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m fp:\n\u001b[0;32m    247\u001b[0m         fp \u001b[39m=\u001b[39m cast(BinaryIO, fp)\n\u001b[1;32m--> 248\u001b[0m         elements \u001b[39m=\u001b[39m _process_pdfminer_pages(\n\u001b[0;32m    249\u001b[0m             fp\u001b[39m=\u001b[39;49mfp,\n\u001b[0;32m    250\u001b[0m             filename\u001b[39m=\u001b[39;49mfilename,\n\u001b[0;32m    251\u001b[0m             encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[0;32m    252\u001b[0m             include_page_breaks\u001b[39m=\u001b[39;49minclude_page_breaks,\n\u001b[0;32m    253\u001b[0m         )\n\u001b[0;32m    255\u001b[0m \u001b[39melif\u001b[39;00m file:\n\u001b[0;32m    256\u001b[0m     fp \u001b[39m=\u001b[39m cast(BinaryIO, file)\n",
            "File \u001b[1;32me:\\Generative AI Projects\\Gradio Chatbot\\venv\\lib\\site-packages\\unstructured\\partition\\pdf.py:276\u001b[0m, in \u001b[0;36m_process_pdfminer_pages\u001b[1;34m(fp, filename, encoding, include_page_breaks)\u001b[0m\n\u001b[0;32m    273\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Uses PDF miner to split a document into pages and process them.\"\"\"\u001b[39;00m\n\u001b[0;32m    274\u001b[0m elements: List[Element] \u001b[39m=\u001b[39m []\n\u001b[1;32m--> 276\u001b[0m \u001b[39mfor\u001b[39;00m i, page \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(extract_pages(fp)):  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[0;32m    277\u001b[0m     metadata \u001b[39m=\u001b[39m ElementMetadata(filename\u001b[39m=\u001b[39mfilename, page_number\u001b[39m=\u001b[39mi \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[0;32m    278\u001b[0m     height \u001b[39m=\u001b[39m page\u001b[39m.\u001b[39mheight\n",
            "File \u001b[1;32me:\\Generative AI Projects\\Gradio Chatbot\\venv\\lib\\site-packages\\pdfminer\\high_level.py:211\u001b[0m, in \u001b[0;36mextract_pages\u001b[1;34m(pdf_file, password, page_numbers, maxpages, caching, laparams)\u001b[0m\n\u001b[0;32m    207\u001b[0m interpreter \u001b[39m=\u001b[39m PDFPageInterpreter(resource_manager, device)\n\u001b[0;32m    208\u001b[0m \u001b[39mfor\u001b[39;00m page \u001b[39min\u001b[39;00m PDFPage\u001b[39m.\u001b[39mget_pages(\n\u001b[0;32m    209\u001b[0m     fp, page_numbers, maxpages\u001b[39m=\u001b[39mmaxpages, password\u001b[39m=\u001b[39mpassword, caching\u001b[39m=\u001b[39mcaching\n\u001b[0;32m    210\u001b[0m ):\n\u001b[1;32m--> 211\u001b[0m     interpreter\u001b[39m.\u001b[39;49mprocess_page(page)\n\u001b[0;32m    212\u001b[0m     layout \u001b[39m=\u001b[39m device\u001b[39m.\u001b[39mget_result()\n\u001b[0;32m    213\u001b[0m     \u001b[39myield\u001b[39;00m layout\n",
            "File \u001b[1;32me:\\Generative AI Projects\\Gradio Chatbot\\venv\\lib\\site-packages\\pdfminer\\pdfinterp.py:997\u001b[0m, in \u001b[0;36mPDFPageInterpreter.process_page\u001b[1;34m(self, page)\u001b[0m\n\u001b[0;32m    995\u001b[0m     ctm \u001b[39m=\u001b[39m (\u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m-\u001b[39mx0, \u001b[39m-\u001b[39my0)\n\u001b[0;32m    996\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice\u001b[39m.\u001b[39mbegin_page(page, ctm)\n\u001b[1;32m--> 997\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrender_contents(page\u001b[39m.\u001b[39;49mresources, page\u001b[39m.\u001b[39;49mcontents, ctm\u001b[39m=\u001b[39;49mctm)\n\u001b[0;32m    998\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice\u001b[39m.\u001b[39mend_page(page)\n\u001b[0;32m    999\u001b[0m \u001b[39mreturn\u001b[39;00m\n",
            "File \u001b[1;32me:\\Generative AI Projects\\Gradio Chatbot\\venv\\lib\\site-packages\\pdfminer\\pdfinterp.py:1016\u001b[0m, in \u001b[0;36mPDFPageInterpreter.render_contents\u001b[1;34m(self, resources, streams, ctm)\u001b[0m\n\u001b[0;32m   1014\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minit_resources(resources)\n\u001b[0;32m   1015\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minit_state(ctm)\n\u001b[1;32m-> 1016\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexecute(list_value(streams))\n\u001b[0;32m   1017\u001b[0m \u001b[39mreturn\u001b[39;00m\n",
            "File \u001b[1;32me:\\Generative AI Projects\\Gradio Chatbot\\venv\\lib\\site-packages\\pdfminer\\pdfinterp.py:1045\u001b[0m, in \u001b[0;36mPDFPageInterpreter.execute\u001b[1;34m(self, streams)\u001b[0m\n\u001b[0;32m   1043\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1044\u001b[0m         log\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mexec: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, name)\n\u001b[1;32m-> 1045\u001b[0m         func()\n\u001b[0;32m   1046\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1047\u001b[0m     \u001b[39mif\u001b[39;00m settings\u001b[39m.\u001b[39mSTRICT:\n",
            "File \u001b[1;32me:\\Generative AI Projects\\Gradio Chatbot\\venv\\lib\\site-packages\\pdfminer\\pdfinterp.py:580\u001b[0m, in \u001b[0;36mPDFPageInterpreter.do_f\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    578\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdo_f\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    579\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Fill path using nonzero winding number rule\"\"\"\u001b[39;00m\n\u001b[1;32m--> 580\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevice\u001b[39m.\u001b[39;49mpaint_path(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgraphicstate, \u001b[39mFalse\u001b[39;49;00m, \u001b[39mTrue\u001b[39;49;00m, \u001b[39mFalse\u001b[39;49;00m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcurpath)\n\u001b[0;32m    581\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurpath \u001b[39m=\u001b[39m []\n\u001b[0;32m    582\u001b[0m     \u001b[39mreturn\u001b[39;00m\n",
            "File \u001b[1;32me:\\Generative AI Projects\\Gradio Chatbot\\venv\\lib\\site-packages\\pdfminer\\converter.py:126\u001b[0m, in \u001b[0;36mPDFLayoutAnalyzer.paint_path\u001b[1;34m(self, gstate, stroke, fill, evenodd, path)\u001b[0m\n\u001b[0;32m    124\u001b[0m     \u001b[39mfor\u001b[39;00m m \u001b[39min\u001b[39;00m re\u001b[39m.\u001b[39mfinditer(\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mm[^m]+\u001b[39m\u001b[39m\"\u001b[39m, shape):\n\u001b[0;32m    125\u001b[0m         subpath \u001b[39m=\u001b[39m path[m\u001b[39m.\u001b[39mstart(\u001b[39m0\u001b[39m) : m\u001b[39m.\u001b[39mend(\u001b[39m0\u001b[39m)]\n\u001b[1;32m--> 126\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpaint_path(gstate, stroke, fill, evenodd, subpath)\n\u001b[0;32m    128\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m     \u001b[39m# Although the 'h' command does not not literally provide a\u001b[39;00m\n\u001b[0;32m    130\u001b[0m     \u001b[39m# point-position, its position is (by definition) equal to the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    134\u001b[0m     \u001b[39m# their point-position in their final two arguments. (Any preceding\u001b[39;00m\n\u001b[0;32m    135\u001b[0m     \u001b[39m# arguments represent control points on Bézier curves.)\u001b[39;00m\n\u001b[0;32m    136\u001b[0m     raw_pts \u001b[39m=\u001b[39m [\n\u001b[0;32m    137\u001b[0m         cast(Point, p[\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m:] \u001b[39mif\u001b[39;00m p[\u001b[39m0\u001b[39m] \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mh\u001b[39m\u001b[39m\"\u001b[39m \u001b[39melse\u001b[39;00m path[\u001b[39m0\u001b[39m][\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m:]) \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m path\n\u001b[0;32m    138\u001b[0m     ]\n",
            "File \u001b[1;32me:\\Generative AI Projects\\Gradio Chatbot\\venv\\lib\\site-packages\\pdfminer\\converter.py:136\u001b[0m, in \u001b[0;36mPDFLayoutAnalyzer.paint_path\u001b[1;34m(self, gstate, stroke, fill, evenodd, path)\u001b[0m\n\u001b[0;32m    126\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpaint_path(gstate, stroke, fill, evenodd, subpath)\n\u001b[0;32m    128\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m     \u001b[39m# Although the 'h' command does not not literally provide a\u001b[39;00m\n\u001b[0;32m    130\u001b[0m     \u001b[39m# point-position, its position is (by definition) equal to the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    134\u001b[0m     \u001b[39m# their point-position in their final two arguments. (Any preceding\u001b[39;00m\n\u001b[0;32m    135\u001b[0m     \u001b[39m# arguments represent control points on Bézier curves.)\u001b[39;00m\n\u001b[1;32m--> 136\u001b[0m     raw_pts \u001b[39m=\u001b[39m [\n\u001b[0;32m    137\u001b[0m         cast(Point, p[\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m:] \u001b[39mif\u001b[39;00m p[\u001b[39m0\u001b[39m] \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mh\u001b[39m\u001b[39m\"\u001b[39m \u001b[39melse\u001b[39;00m path[\u001b[39m0\u001b[39m][\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m:]) \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m path\n\u001b[0;32m    138\u001b[0m     ]\n\u001b[0;32m    139\u001b[0m     pts \u001b[39m=\u001b[39m [apply_matrix_pt(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mctm, pt) \u001b[39mfor\u001b[39;00m pt \u001b[39min\u001b[39;00m raw_pts]\n\u001b[0;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m shape \u001b[39min\u001b[39;00m {\u001b[39m\"\u001b[39m\u001b[39mmlh\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mml\u001b[39m\u001b[39m\"\u001b[39m}:\n\u001b[0;32m    142\u001b[0m         \u001b[39m# single line segment\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         \u001b[39m#\u001b[39;00m\n\u001b[0;32m    144\u001b[0m         \u001b[39m# Note: 'ml', in conditional above, is a frequent anomaly\u001b[39;00m\n\u001b[0;32m    145\u001b[0m         \u001b[39m# that we want to support.\u001b[39;00m\n",
            "File \u001b[1;32me:\\Generative AI Projects\\Gradio Chatbot\\venv\\lib\\site-packages\\pdfminer\\converter.py:137\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    126\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpaint_path(gstate, stroke, fill, evenodd, subpath)\n\u001b[0;32m    128\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m     \u001b[39m# Although the 'h' command does not not literally provide a\u001b[39;00m\n\u001b[0;32m    130\u001b[0m     \u001b[39m# point-position, its position is (by definition) equal to the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    134\u001b[0m     \u001b[39m# their point-position in their final two arguments. (Any preceding\u001b[39;00m\n\u001b[0;32m    135\u001b[0m     \u001b[39m# arguments represent control points on Bézier curves.)\u001b[39;00m\n\u001b[0;32m    136\u001b[0m     raw_pts \u001b[39m=\u001b[39m [\n\u001b[1;32m--> 137\u001b[0m         cast(Point, p[\u001b[39m-\u001b[39;49m\u001b[39m2\u001b[39;49m:] \u001b[39mif\u001b[39;49;00m p[\u001b[39m0\u001b[39;49m] \u001b[39m!=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mh\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39melse\u001b[39;49;00m path[\u001b[39m0\u001b[39;49m][\u001b[39m-\u001b[39;49m\u001b[39m2\u001b[39;49m:]) \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m path\n\u001b[0;32m    138\u001b[0m     ]\n\u001b[0;32m    139\u001b[0m     pts \u001b[39m=\u001b[39m [apply_matrix_pt(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mctm, pt) \u001b[39mfor\u001b[39;00m pt \u001b[39min\u001b[39;00m raw_pts]\n\u001b[0;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m shape \u001b[39min\u001b[39;00m {\u001b[39m\"\u001b[39m\u001b[39mmlh\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mml\u001b[39m\u001b[39m\"\u001b[39m}:\n\u001b[0;32m    142\u001b[0m         \u001b[39m# single line segment\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         \u001b[39m#\u001b[39;00m\n\u001b[0;32m    144\u001b[0m         \u001b[39m# Note: 'ml', in conditional above, is a frequent anomaly\u001b[39;00m\n\u001b[0;32m    145\u001b[0m         \u001b[39m# that we want to support.\u001b[39;00m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Data Ingestion\n",
        "from langchain.document_loaders import DirectoryLoader\n",
        "#from langchain.document_loaders import PyPDFLoader\n",
        "#below directory loader not working with pdf file for some reason, so using PDFMinerLoader temporarily\n",
        "pdf_loader = DirectoryLoader('./Reports', glob=\"**/*.pdf\")\n",
        "txt_loader = DirectoryLoader('./Reports', glob=\"**/*.txt\")\n",
        "word_loader = DirectoryLoader('./Reports', glob=\"**/*.docx\")\n",
        "\n",
        "#pdf_loader = PyPDFLoader(\"E:\\Generative AI Projects\\Gradio Chatbot\\GradioChatbotRetrieval\\Reports\\Star_Atlas_ economics-paper.pdf\")\n",
        "\n",
        "loaders = [pdf_loader, txt_loader, word_loader]\n",
        "#loaders = [txt_loader, word_loader]\n",
        "#loaders = [pdf_loader]\n",
        "documents = []\n",
        "for loader in loaders:\n",
        "    documents.extend(loader.load())\n",
        "\n",
        "print(f\"Total number of documents: {len(documents)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "BaJ4O4R6ENsw"
      },
      "outputs": [],
      "source": [
        "# Chunk and Embeddings\n",
        "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "documents = text_splitter.split_documents(documents)\n",
        "\n",
        "embeddings = OpenAIEmbeddings()\n",
        "vectorstore = Chroma.from_documents(documents, embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "k-ADRjHdEX6P"
      },
      "outputs": [],
      "source": [
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "# Initialise Langchain - Conversation Retrieval Chain\n",
        "#qa = ConversationalRetrievalChain.from_llm(ChatOpenAI(temperature=0), vectorstore.as_retriever(), return_source_documents=True)\n",
        "\n",
        "memory = ConversationBufferMemory(\n",
        "        memory_key='chat_history', return_messages=True, output_key='answer')\n",
        "qa = ConversationalRetrievalChain.from_llm(\n",
        "    ChatOpenAI(temperature=0), \n",
        "    vectorstore.as_retriever(), \n",
        "    memory=memory,\n",
        "    get_chat_history=lambda h : h,\n",
        "    return_source_documents=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 634
        },
        "id": "goQwW0FkFBxC",
        "outputId": "d3b39b60-b4fb-4de2-acba-3db449856453"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running on local URL:  http://127.0.0.1:7860\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Keyboard interruption in main thread... closing server.\n"
          ]
        }
      ],
      "source": [
        "# Front end web app\n",
        "from langchain.memory import ChatMessageHistory\n",
        "from langchain.schema import messages_from_dict, messages_to_dict\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chains import ConversationChain\n",
        "\n",
        "\n",
        "import gradio as gr\n",
        "with gr.Blocks() as demo:\n",
        "    chatbot = gr.Chatbot()\n",
        "    msg = gr.Textbox()\n",
        "    clear = gr.Button(\"Clear\")\n",
        "    #chat_history = ()\n",
        "    context = ChatMessageHistory()\n",
        "    memory = ConversationBufferMemory(\n",
        "        memory_key='chat_history', return_messages=True, output_key='answer')\n",
        "    \n",
        "    def respond(user_message, chat_history):\n",
        " \n",
        "        # Get response from QA chain\n",
        "        response = qa({\"question\": user_message, \"chat_history\": chat_history})\n",
        "        # Append user message and response to chat history\n",
        "        chat_history.append((user_message, response[\"answer\"]))\n",
        "        return gr.update(value=\"\"), chat_history\n",
        "    msg.submit(respond, [msg, chatbot], [msg, chatbot], queue=False)\n",
        "    clear.click(lambda: None, None, chatbot, queue=False)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    demo.launch(debug=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ISjWHiOS5LUU"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPmyu9Z273BU4aRBIAKLqoZ",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
